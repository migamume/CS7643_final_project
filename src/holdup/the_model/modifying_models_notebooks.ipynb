{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "095f454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from holdup.the_model.autoencoder2 import Autoencoder\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "from holdup.parser.replayable_hand import ReplayableHand, Streets\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "417f2d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_size: 32400\n",
      "test_data_size: 21600\n"
     ]
    }
   ],
   "source": [
    "'''Data prep\n",
    "Reconstruct 20x20 matrix \n",
    "np or torch.reshape((20,20))\n",
    "Look at this line: https://github.com/migamume/CS7643_final_project/blob/main/src/holdup/parser/data_prepper.py#L95\n",
    "\n",
    "Split dataset -> 60 train, 40 test'''\n",
    "\n",
    "# Set up paths and filenames - change to pased data file -> CS7643_final_project/src/holdup/parser/data/acpc_2011_2p_nolimit/parsed\n",
    "data_dir = '/Users/pc/Desktop/Deep Learning/Project Github/CS7643_final_project/src/holdup/parser/data/acpc_2011_2p_nolimit/parsed'\n",
    "# Set up train-test split\n",
    "split_test_train = 6 #6 == 60% of data will be used for training\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Iterate over CSV files\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "random.shuffle(csv_files)\n",
    "\n",
    "for i, csv_file in enumerate(csv_files):\n",
    "    # Load CSV file\n",
    "    data = np.loadtxt(os.path.join(data_dir, csv_file), delimiter=',')\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        sub_data = np.reshape(data[j], (20,20))\n",
    "        \n",
    "        if j < 6:\n",
    "            train_data.append(sub_data)\n",
    "        else:\n",
    "            test_data.append(sub_data)\n",
    "            \n",
    "print(\"train_data_size: {}\".format(len(train_data)))\n",
    "print(\"test_data_size: {}\".format(len(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1faf3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert training/test data into tensors\n",
    "train_tensor = torch.tensor(train_data)\n",
    "test_tensor = torch.tensor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7dba5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#number of hidden nodes for the unsupervised learning model: Use 20 or 40\n",
    "unsupervised_hidden_nodes = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cecc61ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00325"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(1e-3 + 0.0055)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5535fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0217\n",
      "Epoch:2, Loss:0.0222\n",
      "Epoch:3, Loss:0.0225\n",
      "Epoch:4, Loss:0.0226\n",
      "Epoch:5, Loss:0.0225\n",
      "Epoch:6, Loss:0.0225\n",
      "Epoch:7, Loss:0.0225\n",
      "Epoch:8, Loss:0.0226\n",
      "Epoch:9, Loss:0.0226\n",
      "Epoch:10, Loss:0.0227\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(unsupervised_hidden_nodes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_tensor:\n",
    "        data = torch.flatten(data)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    outputs.append((epoch, data, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f89e2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"encoder.0.bias\":\n",
    "        lst.append(param)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5664295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_transform = lst[0]\n",
    "\n",
    "input_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8cae71a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Autoencoder' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder.0.bias\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Autoencoder' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.named_parameters[\"encoder.0.bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7033998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=40, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=40, out_features=400, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec2cf0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b476ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hidden_nodes = 20\n",
    "\n",
    "model = Autoencoder(unsupervised_hidden_nodes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b7e2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, num_epochs, weight_decay):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            inputs = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    Autoencoder.save('autoencoder_model.h5')\n",
    "    print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81eede28",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m train(model, train_tensor, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, num_epochs, weight_decay)\u001b[0m\n\u001b[1;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, inputs)\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dlproject/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Deep Learning/Project Github/CS7643_final_project/src/holdup/the_model/autoencoder.py:23\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x) \u001b[38;5;66;03m#hidden level for auto-encoder (this will be the input for the supervised learning model)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded)\n\u001b[1;32m     25\u001b[0m     softmax_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(encoded)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dlproject/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dlproject/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dlproject/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dlproject/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "x = train(model, train_tensor, 10, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34c53abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32400, 20, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c35f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(unsupervised_hidden_nodes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57132ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0103\n",
      "Epoch:2, Loss:0.0103\n",
      "Epoch:3, Loss:0.0102\n",
      "Epoch:4, Loss:0.0102\n",
      "Epoch:5, Loss:0.0102\n",
      "Epoch:6, Loss:0.0102\n",
      "Epoch:7, Loss:0.0102\n",
      "Epoch:8, Loss:0.0102\n",
      "Epoch:9, Loss:0.0102\n",
      "Epoch:10, Loss:0.0102\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(unsupervised_hidden_nodes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "outputs = []\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_tensor:\n",
    "        data = torch.flatten(data)\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    outputs.append((epoch, data, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb207685",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_tensor:\n",
    "    x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13754f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.reshape(x, (1,400))\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b758391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.flatten(x)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "081a2ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0.]),\n",
       "  tensor([ 1.3566e-01,  4.1496e-02,  1.0676e-01, -4.7465e-04,  8.4506e-02,\n",
       "           7.9150e-02, -6.3834e-02, -1.5535e-02,  3.3133e-03,  6.4619e-02,\n",
       "          -6.7360e-03,  3.4786e-02,  1.3268e-01,  4.0586e-01, -7.1951e-02,\n",
       "           1.4409e-01,  8.5021e-01, -5.3980e-03,  5.9744e-03,  1.3070e-02,\n",
       "          -1.7119e-02,  1.6052e-02, -1.2896e-01,  3.2218e-01, -3.4709e-02,\n",
       "          -1.4682e-02,  3.9189e-02, -8.0769e-02,  9.3756e-02,  4.0027e-02,\n",
       "          -2.6569e-02,  2.8141e-02,  1.0058e-01,  5.1066e-02, -6.4633e-03,\n",
       "          -1.9788e-02,  5.5946e-02, -3.4616e-04,  2.5775e-03,  2.9417e-04,\n",
       "          -5.2327e-02,  5.7645e-02,  1.8247e-01,  7.5552e-02,  1.1629e-01,\n",
       "           9.2335e-02,  1.9131e-02,  8.3776e-02,  3.6246e-02, -3.1824e-02,\n",
       "          -1.8601e-02,  3.9836e-02,  9.3062e-02, -9.9456e-03, -9.7545e-03,\n",
       "          -7.5791e-02,  1.6075e-02, -4.8485e-03, -1.8200e-03, -8.8566e-03,\n",
       "          -1.5410e-02,  7.6495e-02,  1.2186e-02, -2.3478e-02,  1.9797e-02,\n",
       "          -1.2707e-02, -1.8873e-01,  1.8816e-02, -4.9376e-02,  1.7482e-02,\n",
       "           2.1984e-01, -1.9237e-02,  2.0723e-01, -7.1900e-03,  1.0259e-02,\n",
       "          -9.4585e-02,  1.4556e-02,  2.6891e-03, -3.6836e-03, -2.4596e-04,\n",
       "          -1.2148e-02,  9.2691e-03,  9.1057e-02, -2.1102e-02,  4.5382e-02,\n",
       "           4.3312e-02, -1.2372e-01,  3.5378e-02,  9.0907e-03,  5.0381e-02,\n",
       "           1.1327e-01,  1.1145e-02,  2.2726e-01,  6.7023e-02,  2.2220e-02,\n",
       "           3.4053e-01,  1.1876e-01,  4.0124e-03, -4.9261e-03,  1.9959e-03,\n",
       "          -3.5228e-02,  2.0482e-02, -5.9512e-02,  2.4036e-01, -2.9713e-02,\n",
       "          -6.9158e-02,  4.6894e-02, -8.2963e-02,  6.6015e-02,  1.7798e-02,\n",
       "          -1.1596e-02,  1.5092e-02,  1.3011e-01, -6.5681e-04, -6.9944e-02,\n",
       "           4.5033e-02,  4.9240e-02,  5.4460e-03,  2.0377e-03, -5.1152e-03,\n",
       "          -3.6005e-02,  4.9678e-02,  1.8731e-01,  9.3456e-02,  4.9486e-02,\n",
       "           9.8342e-02, -1.5283e-02,  1.0428e-01,  9.5563e-02, -6.8830e-02,\n",
       "          -5.5479e-03,  1.6888e-01,  9.5314e-02, -2.0422e-02, -7.1219e-02,\n",
       "           4.7468e-03, -8.3873e-03,  1.1006e-02,  5.9510e-03, -2.2702e-03,\n",
       "          -4.6637e-03,  6.0403e-02,  4.4951e-03, -2.3298e-02,  2.8861e-02,\n",
       "          -2.3797e-02, -1.3333e-01,  5.9028e-02, -2.9836e-02,  6.8890e-03,\n",
       "           1.5073e-01,  2.5470e-02,  2.2389e-01, -2.3008e-02, -6.7059e-02,\n",
       "           1.2755e-02, -2.9790e-02, -3.8496e-03, -7.5894e-03,  4.5993e-03,\n",
       "           8.6368e-01,  3.5785e-02,  9.5351e-04, -3.1416e-04, -9.2215e-03,\n",
       "           2.6951e-03,  3.7805e-06, -4.8111e-03, -4.8853e-03, -3.6188e-09,\n",
       "           2.5290e-03,  3.4195e-02,  1.4602e-05,  7.1596e-08,  1.1635e-02,\n",
       "           2.7914e-08,  1.0753e-14, -1.6721e-03,  5.7185e-04,  7.8574e-03,\n",
       "           1.8752e-01,  2.1737e-01,  7.6663e-02, -3.9946e-04, -6.4228e-03,\n",
       "          -1.0680e-07,  1.4350e-05,  3.1018e-10, -3.5133e-05, -7.6979e-06,\n",
       "           4.2049e-03, -1.7704e-12,  1.4237e-05,  6.9747e-08,  4.1686e-05,\n",
       "           4.0410e-03, -2.4149e-11, -6.2030e-03, -7.9238e-03,  9.0533e-02,\n",
       "           5.0520e-02, -6.3598e-02, -1.0229e-02, -7.0549e-03, -2.0402e-03,\n",
       "          -5.1785e-04, -1.9728e-04, -1.3842e-04,  1.0723e-02, -7.9319e-05,\n",
       "           1.3493e-02,  1.4914e-04,  6.3350e-03, -7.2646e-03,  3.3623e-03,\n",
       "           4.1559e-04,  9.4411e-03,  4.6531e-14, -4.9476e-03,  3.8385e-02,\n",
       "           4.8495e-02, -6.7668e-02,  1.7067e-02, -1.4970e-03, -4.7375e-03,\n",
       "          -2.1736e-04, -7.4573e-03,  1.8148e-08, -5.2605e-03,  8.4787e-06,\n",
       "           5.9829e-03, -4.8202e-04, -1.0227e-03, -2.5347e-07,  2.4080e-03,\n",
       "           2.5445e-04,  3.0682e-12, -4.1494e-04, -1.1825e-02,  3.3280e-02,\n",
       "          -6.8475e-03, -8.2169e-03, -2.3710e-02, -3.3110e-02, -7.5146e-03,\n",
       "          -6.3725e-03, -1.1564e-06,  5.2784e-10, -2.8449e-05,  4.6873e-06,\n",
       "          -2.0097e-06,  4.0446e-03,  7.5874e-07,  4.2961e-07,  3.5076e-04,\n",
       "          -2.9297e-03, -3.8168e-06, -8.7272e-12,  2.4134e-04, -3.5386e-03,\n",
       "          -2.6059e-02, -7.4817e-03, -1.4743e-02, -2.5013e-02, -4.8650e-03,\n",
       "          -1.1776e-02,  3.4924e-04, -7.1809e-08, -3.3590e-05,  4.5526e-06,\n",
       "          -3.6335e-07,  4.0447e-03, -1.7993e-11, -1.1068e-08,  2.8243e-04,\n",
       "          -4.2661e-03, -6.3978e-06,  3.9759e-04,  2.2508e-04,  1.4687e-03,\n",
       "          -7.8198e-03, -5.3623e-03, -3.3589e-02, -3.0257e-04,  2.0100e-03,\n",
       "          -1.3139e-03, -1.7723e-02, -1.0005e-02, -6.0004e-03,  2.6447e-03,\n",
       "          -2.9275e-04, -8.2028e-06, -7.1902e-07,  2.5631e-04, -1.5428e-04,\n",
       "          -1.0726e-03, -7.8278e-05, -5.0050e-09,  4.6127e-12, -1.2882e-02,\n",
       "          -5.2591e-02,  2.6170e-02, -2.0176e-02, -2.2423e-03, -4.4867e-03,\n",
       "          -5.2040e-03, -8.2317e-03, -1.0726e-02, -4.1644e-03, -4.8876e-03,\n",
       "          -3.1460e-04, -9.3180e-06, -5.4218e-06,  2.5631e-04, -1.6211e-04,\n",
       "          -3.9005e-03, -8.9545e-05, -1.1380e-08, -9.3488e-12, -1.0468e-02,\n",
       "           3.4956e-03,  1.0406e-02, -4.7420e-03, -4.8824e-03,  5.3589e-03,\n",
       "           4.9975e-03, -6.8909e-04,  4.3426e-03, -1.7111e-03, -4.1060e-03,\n",
       "           4.1001e-03, -2.8843e-03, -2.8374e-03, -4.2600e-03, -1.1185e-02,\n",
       "          -7.1536e-03,  3.4932e-03, -8.5730e-03, -3.1404e-04,  4.3725e-03,\n",
       "          -8.8604e-03, -4.1034e-03,  3.7271e-03,  5.5944e-04, -1.4378e-04,\n",
       "           2.3703e-03, -2.2510e-03, -2.4717e-03,  8.1669e-03,  6.2006e-03,\n",
       "          -2.1670e-03, -1.4658e-04,  3.1439e-03, -6.3868e-05,  2.4995e-04,\n",
       "           8.6808e-03,  8.9388e-03, -7.9817e-03,  9.0700e-03,  4.0324e-03,\n",
       "           8.8589e-03,  6.9957e-03,  9.1533e-03,  4.3752e-03, -6.3521e-03,\n",
       "          -9.0443e-03,  4.4683e-03,  1.2052e-04,  3.1267e-03,  6.6877e-03,\n",
       "          -2.8160e-03, -2.0984e-03,  4.0812e-04,  8.3222e-03,  7.4881e-03,\n",
       "          -2.3042e-04,  4.6141e-03,  9.3329e-03, -2.7416e-03,  2.4438e-03,\n",
       "           9.0744e-03, -7.1247e-03,  6.2921e-03, -6.1739e-03, -1.2182e-04,\n",
       "           4.2087e-03,  5.3219e-03,  6.9493e-04,  1.4812e-03, -2.4114e-04,\n",
       "           2.9780e-03, -7.1443e-03, -1.3058e-03, -1.2582e-03, -4.9854e-03,\n",
       "          -5.6291e-03, -9.1041e-04, -4.4564e-03, -9.9223e-03, -3.2438e-03],\n",
       "         grad_fn=<AddBackward0>))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f496300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
